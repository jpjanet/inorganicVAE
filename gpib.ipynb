{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msk[8] = True\n",
      "normalizing with number of dimensions = 155\n",
      "normalizing with number of dimensions = 155\n",
      "normalizing with number of dimensions = 1\n",
      "normalizing with number of dimensions = 1\n",
      "(983, 155)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## based on \n",
    "# https://danijar.com/building-variational-auto-encoders-in-tensorflow/\n",
    "# https://towardsdatascience.com/teaching-a-variational-autoencoder-vae-to-draw-mnist-characters-978675c95776\n",
    "## Imports\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import sklearn.model_selection\n",
    "import os, glob, shutil, math, time\n",
    "# reset tf graph  \n",
    "tf.reset_default_graph()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "#sess = tf.Session()\n",
    "session = tf.InteractiveSession()\n",
    "## data pipeline from R-prepared CSV\n",
    "\n",
    "df = pd.read_csv(\"split_x.csv\",sep=\",\")\n",
    "data = df.values\n",
    "odf = pd.read_csv(\"split_y.csv\",sep=\",\")\n",
    "outcomes = odf.values\n",
    "\n",
    "\n",
    "## seed \n",
    "np.random.seed(134)\n",
    "\n",
    "m = np.shape(data)[0]\n",
    "d = np.shape(data)[1]\n",
    "p = 1\n",
    "\n",
    "## Functions\n",
    "def data_rescale(scaled_dat,train_mean,train_var):\n",
    "    d = np.shape(train_mean)[0]\n",
    "#     print('unnormalizing with number of dimensions = ' +str(d))\n",
    "    dat = (np.multiply(scaled_dat.T,np.sqrt(train_var),)+train_mean).T\n",
    "    return(dat)\n",
    "\n",
    "def data_normalize(data,train_mean,train_var):\n",
    "    d = np.shape(train_mean)[0]\n",
    "    print('normalizing with number of dimensions = ' +str(d))\n",
    "    scaled_dat = np.divide((data.T - train_mean),np.sqrt(train_var),).T\n",
    "    return(scaled_dat)\n",
    "    \n",
    "## data generation\n",
    "# get random partition\n",
    "msk = np.random.rand(np.shape(data)[0]) < 0.70\n",
    "print('msk[8] = ' + str(msk[8]))\n",
    "\n",
    "# test and train split\n",
    "train_data_x = data[msk]\n",
    "test_data_x = data[~msk]\n",
    "train_data_y = outcomes[msk]\n",
    "test_data_y = outcomes[~msk]\n",
    "\n",
    "\n",
    "\n",
    "# non-dimenisionalization\n",
    "train_var_x = np.var(train_data_x,0).reshape(d,1)\n",
    "train_mean_x = np.mean(train_data_x,0).reshape(d,1)\n",
    "scaled_train_data_x = data_normalize(train_data_x,train_mean_x,train_var_x)\n",
    "scaled_test_data_x = data_normalize(test_data_x,train_mean_x,train_var_x)\n",
    "\n",
    "train_var_y = np.var(train_data_y,0).reshape(p,1)\n",
    "train_mean_y = np.mean(train_data_y,0).reshape(p,1)\n",
    "scaled_train_data_y = data_normalize(train_data_y,train_mean_y,train_var_y)\n",
    "scaled_test_data_y = data_normalize(test_data_y,train_mean_y,train_var_y)\n",
    "\n",
    "# scaled_train_data_x = np.array([[1,2,3,1],[2,3,4,1],[6,1,2,1]])\n",
    "# scaled_train_data_y =tf.reshape(np.array([0.5,0.58,0.77]),shape=[3,1])\n",
    "# scaled_test_data_x = np.array([[9,7,8,2],[8,2,2,1]])\n",
    "# scaled_test_data_y = tf.reshape(np.array([0.55,0.8]),shape=[2,1])\n",
    "# d = 3\n",
    "n_input = d # data input (img shape: 28*28)\n",
    "n =  np.shape(scaled_train_data_x)[0]\n",
    "ntest =  np.shape(scaled_test_data_x)[0]\n",
    "\n",
    "## tf variable placeholders for feeding\n",
    "with tf.name_scope('input'):\n",
    "    X = tf.placeholder(tf.float32,[None,n_input],name=\"X\")\n",
    "    Y = tf.placeholder(tf.float32,[None,n_input],name=\"Y\")\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    keep_prob = tf.placeholder(dtype=tf.float32, shape=(), name='keep_prob')\n",
    "\n",
    "print(scaled_train_data_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myPairwiseDist(X,Y):\n",
    "    tile1 = tf.tile(tf.expand_dims(X, 0), [Y.shape[0], 1, 1])\n",
    "    tile2 = tf.tile(tf.expand_dims(Y, 1), [1,X.shape[0] , 1])\n",
    "    pairwiseEuclideanDistance = tf.reduce_sum(tf.square(tf.subtract(tile1, tile2)), 2)\n",
    "    return pairwiseEuclideanDistance\n",
    "def myRBFKernel(gamma,X,Y):\n",
    "    K = tf.exp(tf.multiply(tf.cast(-1*gamma,dtype=\"float64\"), tf.cast(myPairwiseDist(X,Y),dtype=\"float64\")))\n",
    "    return K\n",
    "def kernelModel(alpha,K):\n",
    "    ymod = tf.matmul(K,alpha)\n",
    "    return ymod\n",
    "def ridgeReg(alpha):\n",
    "    penalty = tf.norm(alpha)\n",
    "    return penalty\n",
    "\n",
    "def objective(alpha,ytrain,K,lam):\n",
    "    o = tf.cast(tf.nn.l2_loss(tf.subtract(ytrain,kernelModel(alpha,K))),dtype=\"float64\") + tf.cast(tf.abs(lam),dtype=\"float64\")*tf.cast(ridgeReg(alpha),dtype=\"float64\")\n",
    "    return o\n",
    "    \n",
    "def predictiveModel(x,alpha,xtrain,gamma):\n",
    "    predK = kernelModel(alpha,myRBFKernel(xtrain,x))\n",
    "    return predK\n",
    "def solveLinearKernel(K,lam,ytrain):\n",
    "    mat = tf.add(tf.matmul(tf.transpose(K),K),lam*tf.eye(num_rows=tf.cast(scaled_train_data_y.shape[0],dtype=\"int32\"),\n",
    "                                                         dtype=\"float64\"))\n",
    "    rhs = tf.matmul(tf.transpose(K),ytrain)\n",
    "    alpha = tf.matrix_solve(mat,rhs)\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 intial weights\n",
    "alpha = tf.Variable(tf.random_normal([n,1],mean=0.0,stddev=1.0,dtype=\"float64\"),name=\"alpha\", dtype=\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set kernel\n",
    "gamma = tf.Variable(1.930698e-02, tf.float64)\n",
    "K  = myRBFKernel(gamma,scaled_train_data_x,scaled_train_data_x)\n",
    "Kt  = myRBFKernel(gamma,scaled_train_data_x,scaled_test_data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "metadata": {},
   "outputs": [],
   "source": [
    "## linear solve\n",
    "lam = tf.Variable(1.668101e-06, tf.float64)\n",
    "bestAlpha = solveLinearKernel(K,1.668101e-06,scaled_train_data_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define performance metrics\n",
    "train_pred = kernelModel(alpha,K)\n",
    "test_pred = kernelModel(alpha,Kt)\n",
    "train_errors = tf.subtract(train_pred,scaled_train_data_y)\n",
    "test_errors = tf.subtract(test_pred,scaled_test_data_y)\n",
    "train_mae = tf.metrics.mean_absolute_error(train_pred,scaled_train_data_y)\n",
    "test_mae = tf.metrics.mean_absolute_error(test_pred,scaled_test_data_y)\n",
    "train_rmse = tf.metrics.mean_squared_error(train_pred*np.sqrt(train_var_y),scaled_train_data_y*np.sqrt(train_var_y))\n",
    "test_rmse = tf.metrics.mean_squared_error(test_pred*np.sqrt(train_var_y),scaled_test_data_y*np.sqrt(train_var_y))\n",
    "\n",
    "\n",
    "## linear solve\n",
    "train_pred_ds = kernelModel(bestAlpha,K)\n",
    "test_pred_ds = kernelModel(bestAlpha,Kt)\n",
    "train_errors_ds = tf.subtract(train_pred_ds,scaled_train_data_y)\n",
    "test_errors_ds = tf.subtract(test_pred_ds,scaled_test_data_y)\n",
    "train_mae_ds = tf.metrics.mean_absolute_error(train_pred_ds,scaled_train_data_y)\n",
    "test_mae_ds = tf.metrics.mean_absolute_error(test_pred_ds,scaled_test_data_y)\n",
    "train_rmse_ds = tf.metrics.mean_squared_error(train_pred_ds*np.sqrt(train_var_y),scaled_train_data_y*np.sqrt(train_var_y))\n",
    "test_rmse_ds = tf.metrics.mean_squared_error(test_pred_ds*np.sqrt(train_var_y),scaled_test_data_y*np.sqrt(train_var_y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build optimizer\n",
    "optimizer =tf.train.AdamOptimizer(learning_rate=1)\n",
    "loss = objective(alpha,scaled_train_data_y,K,lam)\n",
    "rt = optimizer.minimize(loss,var_list=[alpha])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize all\n",
    "init = tf.global_variables_initializer()\n",
    "init_l = tf.local_variables_initializer()\n",
    "session.run(init)\n",
    "session.run(init_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting at loss: 13572.969553468789 err 18187.173681824635 gamma 0.01930698\n"
     ]
    }
   ],
   "source": [
    "alpha_err = tf.reduce_sum(tf.abs(tf.subtract(alpha,bestAlpha)))\n",
    "print(\"starting at\", \"loss:\", session.run(loss),'err',session.run(alpha_err),'gamma',session.run(gamma))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss: 64.10745350287264 gamma 0.01930698 lambda 1.668101e-06\n",
      "step 100 loss: 49.860938387185065 gamma 0.01930698 lambda 1.668101e-06\n",
      "step 200 loss: 47.253932326200655 gamma 0.01930698 lambda 1.668101e-06\n",
      "step 300 loss: 2258.261953474609 gamma 0.01930698 lambda 1.668101e-06\n",
      "step 400 loss: 232.0811268992046 gamma 0.01930698 lambda 1.668101e-06\n",
      "step 500 loss: 12572.382809064477 gamma 0.01930698 lambda 1.668101e-06\n",
      "step 600 loss: 39.56998783084887 gamma 0.01930698 lambda 1.668101e-06\n",
      "step 700 loss: 170.21020646795384 gamma 0.01930698 lambda 1.668101e-06\n",
      "step 800 loss: 37.18586976559926 gamma 0.01930698 lambda 1.668101e-06\n",
      "step 900 loss: 1089.085788523047 gamma 0.01930698 lambda 1.668101e-06\n",
      "step 1000 loss: 35.45129074116178 gamma 0.01930698 lambda 1.668101e-06\n",
      "step 1100 loss: 34.377968629065705 gamma 0.01930698 lambda 1.668101e-06\n",
      "step 1200 loss: 37.04460889947174 gamma 0.01930698 lambda 1.668101e-06\n",
      "step 1300 loss: 33.11816187716755 gamma 0.01930698 lambda 1.668101e-06\n",
      "step 1400 loss: 32.41677110573576 gamma 0.01930698 lambda 1.668101e-06\n"
     ]
    }
   ],
   "source": [
    "for step in range(1500):  \n",
    "  session.run(rt)\n",
    "  if not step % 100:\n",
    "#       print(\"step\", step, \"loss:\", session.run(loss),'err',session.run(alpha_err))\n",
    "        print(\"step\", step, \"loss:\", session.run(loss),'gamma',session.run(gamma),'lambda',session.run(lam))\n",
    "#print(\"x:\", session.run(alpha))\n",
    "#print('best x',session.run(bestAlpha))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train op done, metrics\n",
      "MAEs [0.22098398, 0.27203837]\n",
      "RMSE [71.5568, 101.97008]\n",
      "train op done, metrics, units\n",
      "MAEs 5.51448304 | 6.85559465\n",
      "RMSE 8.0526905 | 9.7313595\n"
     ]
    }
   ],
   "source": [
    "print('train op done, metrics' )\n",
    "print('MAEs',[session.run(train_mae)[1],session.run(test_mae)[1]])\n",
    "print('RMSE',[session.run(train_rmse)[1],session.run(test_rmse)[1]])\n",
    "\n",
    "print('train op done, metrics, units' )\n",
    "resc =  lambda x: str(x*np.sqrt(train_var_y)).strip('[]')\n",
    "print('MAEs',resc(session.run(train_mae)[1]),\"|\",resc(session.run(test_mae)[1]))\n",
    "print('RMSE',np.sqrt(session.run(train_rmse)[1]),\"|\",np.sqrt(session.run(test_rmse)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train op done, metrics, units, linear solve\n",
      "MAEs 0.67358796 | 3.31031016\n",
      "RMSE 1.369667 | 6.523318\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('train op done, metrics, units, linear solve' )\n",
    "resc =  lambda x: str(x*np.sqrt(train_var_y)).strip('[]')\n",
    "print('MAEs',resc(session.run(train_mae_ds)[1]),\"|\",resc(session.run(test_mae_ds)[1]))\n",
    "print('RMSE',np.sqrt(session.run(train_rmse_ds)[1]),\"|\",np.sqrt(session.run(test_rmse_ds)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.25909194"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt((6.25909194**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25.70649411]])"
      ]
     },
     "execution_count": 942,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(train_var_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.875613548755723"
      ]
     },
     "execution_count": 1100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean(np.power(test_errors.eval()*np.sqrt(train_var_y),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensvae]",
   "language": "python",
   "name": "conda-env-tensvae-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
